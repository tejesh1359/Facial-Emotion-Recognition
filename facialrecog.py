# -*- coding: utf-8 -*-
"""FacialRecog.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vvD6JB1DewBgRv4lVwodvrcWjlYQREq5
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# to go to the created folder in drive
# %cd drive/MyDrive/facialRecognition/

# to check where we are
!ls

# extract tar files using this lib
import tarfile
fname = 'fer2013.tar.gz'
if fname.endswith("tar.gz"):
    tar = tarfile.open(fname, "r:gz")
    tar.extractall()
    tar.close()
elif fname.endswith("tar"):
    tar = tarfile.open(fname, "r:")
    tar.extractall()
    tar.close()

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from matplotlib import pyplot
from sklearn.model_selection import train_test_split

# reading the dataset, pixel size is 48x48
df = pd.read_csv('fer2013/fer2013.csv')
df.head()

# different emotions
df.emotion.unique()
# taking the emotions as a dictionary
label_to_text = {0:'anger', 1:'disgust', 2:'fear', 3:'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}

# converting to numpy array, converting to float type because with int type image doesn't show
np.array(df.pixels.loc[0].split(' ')).reshape(48,48).astype('float')

# just to see how the image is :
pyplot.imshow(np.array(df.pixels.loc[0].split(' ')).reshape(48,48).astype('float'))

# for the visual purpose of few images at a time
fig = pyplot.figure(1, (14, 14))
k = 0
for label in sorted(df.emotion.unique()):
    for j in range(3):
        px = df[df.emotion==label].pixels.iloc[k]
        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')
        k += 1
        ax = pyplot.subplot(7, 7, k)
        ax.imshow(px)
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_title(label_to_text[label])
        pyplot.tight_layout()

# applying to all the 36k rows in the dataset
img_array = df.pixels.apply(lambda x: np.array(x.split(' ')).reshape(48, 48,1).astype('float32'))

# converting the shape of the image from single line to 48x48
img_array = np.stack(img_array, axis=0)

# just to check how the image looks
pyplot.imshow(img_array[20000])

# finding the labels for each image(35887 labels)
labels = df.emotion.values

# breaking the dataset into training and testing dataset using sklearn lib
# X_train, y_train, X_test, y_test
X_train,X_test, y_train, y_test = train_test_split(img_array,labels,test_size = 0.1)

#checking the shapes of the train and test
X_train.shape,X_test.shape, y_train.shape, y_test.shape

# normalizing the training and testing values
X_train = X_train/255
X_test = X_test/255

# constructing the CNN
basemodel = tf.keras.models.Sequential()
basemodel.add(tf.keras.layers.Conv2D(32,(3,3), activation='relu', input_shape = (48,48,1)))
basemodel.add(tf.keras.layers.MaxPool2D((2,2)))
basemodel.add(tf.keras.layers.BatchNormalization())
# good practice to increase the no of filters as we go deeper into the layers
basemodel.add(tf.keras.layers.Conv2D(64,(3,3), activation='relu', input_shape = (48,48,1)))
basemodel.add(tf.keras.layers.MaxPool2D((2,2)))
basemodel.add(tf.keras.layers.BatchNormalization())
basemodel.add(tf.keras.layers.Conv2D(128,(3,3), activation='relu', input_shape = (48,48,1)))
basemodel.add(tf.keras.layers.MaxPool2D((2,2)))
#basemodel.add(tf.keras.layers.BatchNormalization())
#flattening
basemodel.add(tf.keras.layers.Flatten())
# adding dense layers with no. of params as output shape of previous layer
basemodel.add(tf.keras.layers.Dense(128,activation='relu'))
# softmax layer with 7 params since output has only 7 classes
basemodel.add(tf.keras.layers.Dense(7, activation='softmax'))

# to check how the model looks
basemodel.summary()

# compiling the model
# sparse_categorical_crossentropy = does one hot vector encoding and then training
# if its already vector encoded then use categorical_crossentropy
basemodel.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss= 'sparse_categorical_crossentropy', metrics= ['accuracy'])

# callback function which checks validation accuracy and save the model
# so creating a folder using os command
# this code below creates the checkpoint folder in the location we are currently, try block to not throw error
try:
  os.mkdir('checkpoint')
except:
  pass

file_name = 'best_model'
checkpoint_path= os.path.join('checkpoint',file_name)


call_back = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, 
                                                 monitor='val_accuracy', 
                                                 verbose=1,
                                                 save_freq='epoch',
                                                 save_best_only=True, 
                                                 save_weights_only=False, 
                                                 mode='max')

X_train.shape

basemodel.fit(X_train,y_train,epochs=20,validation_split=0.3,callbacks=call_back)

#printing the faces
final_model = tf.keras.models.load_model(checkpoint_path)
from IPython.display import clear_output
import time
for k in range(20):
  print(f'actual label is {label_to_text[y_test[k]]}')
  predicted_class = final_model.predict(tf.expand_dims(X_test[k],0)).argmax()
  print(f'predicted label is {label_to_text[predicted_class]}')
  pyplot.imshow(X_test[k].reshape(48,48))
  pyplot.show()
  time.sleep(5)
  clear_output(wait=True)

